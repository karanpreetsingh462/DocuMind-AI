{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68991fb-798c-42a5-b7cd-58842b28e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "810a6130-7c4e-4e8b-9d93-e13bd5505b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-0.3.0-py3-none-any.whl.metadata (996 bytes)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.65 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain-huggingface) (0.3.68)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain-huggingface) (0.21.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.30.2 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain-huggingface) (0.33.4)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.4.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (4.12.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2025.5.1)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.30.2->langchain-huggingface) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\asus\\anaconda3\\envs\\rag_env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.3.0)\n",
      "Downloading langchain_huggingface-0.3.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: langchain-huggingface\n",
      "Successfully installed langchain-huggingface-0.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2843ebc7-9870-494d-9bc1-e1328c68c531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Import all necessary libraries\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "from pathlib import Path\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Other imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23d71312-b97e-487b-8bc0-b799e5ce23e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully!\n",
      "Model: gemma2:2b\n",
      "Embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
      "Chunk size: 1000\n",
      "Top K retrieval: 4\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Configuration settings\n",
    "class RAGConfig:\n",
    "    def __init__(self):\n",
    "        # Model settings\n",
    "        self.model_name = \"gemma2:2b\"\n",
    "        self.embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        \n",
    "        # Text splitting settings\n",
    "        self.chunk_size = 1000\n",
    "        self.chunk_overlap = 200\n",
    "        \n",
    "        # Retrieval settings\n",
    "        self.top_k = 4\n",
    "        self.similarity_threshold = 0.7\n",
    "        \n",
    "        # Vector store settings\n",
    "        self.vector_store_path = \"vector_store\"\n",
    "        \n",
    "        # Memory settings\n",
    "        self.memory_key = \"chat_history\"\n",
    "        self.return_messages = True\n",
    "\n",
    "config = RAGConfig()\n",
    "print(\"Configuration loaded successfully!\")\n",
    "print(f\"Model: {config.model_name}\")\n",
    "print(f\"Embedding model: {config.embedding_model}\")\n",
    "print(f\"Chunk size: {config.chunk_size}\")\n",
    "print(f\"Top K retrieval: {config.top_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df74ece-0b0c-4c43-b920-3de6a8b1d5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Test Response: I am doing well! ðŸ˜Š  \n",
      "\n",
      "How can I help you today? \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Initialize models and embeddings\n",
    "def initialize_models():\n",
    "    try:\n",
    "        # Initialize Ollama LLM\n",
    "        llm = OllamaLLM(\n",
    "            model=config.model_name,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            num_ctx=4096\n",
    "        )\n",
    "        \n",
    "        # Test the model\n",
    "        test_response = llm.invoke(\"Hello, how are you?\")\n",
    "        print(f\"LLM Test Response: {test_response[:100]}...\")\n",
    "        \n",
    "        # Initialize embeddings\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=config.embedding_model,\n",
    "            model_kwargs={'device': 'cpu'},\n",
    "            encode_kwargs={'normalize_embeddings': True}\n",
    "        )\n",
    "        \n",
    "        # Test embeddings\n",
    "        test_embedding = embeddings.embed_query(\"test query\")\n",
    "        print(f\"Embedding dimension: {len(test_embedding)}\")\n",
    "        \n",
    "        return llm, embeddings\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing models: {e}\")\n",
    "        print(\"Make sure Ollama is running and gemma2:2b is installed\")\n",
    "        return None, None\n",
    "\n",
    "llm, embeddings = initialize_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e321ee-e7e5-410f-b826-e7c5549c2939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Document processing functions\n",
    "def load_pdf_documents(pdf_paths: List[str]) -> List[Document]:\n",
    "    \"\"\"Load PDF documents from given paths\"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    for pdf_path in pdf_paths:\n",
    "        try:\n",
    "            loader = PyPDFLoader(pdf_path)\n",
    "            docs = loader.load()\n",
    "            \n",
    "            # Add metadata to identify source\n",
    "            for doc in docs:\n",
    "                doc.metadata['source_file'] = os.path.basename(pdf_path)\n",
    "            \n",
    "            documents.extend(docs)\n",
    "            print(f\"Loaded {len(docs)} pages from {pdf_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {pdf_path}: {e}\")\n",
    "    \n",
    "    return documents\n",
    "\n",
    "def split_documents(documents: List[Document]) -> List[Document]:\n",
    "    \"\"\"Split documents into chunks\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=config.chunk_size,\n",
    "        chunk_overlap=config.chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    splits = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(splits)} chunks\")\n",
    "    \n",
    "    return splits\n",
    "\n",
    "def create_vector_store(documents: List[Document], embeddings) -> FAISS:\n",
    "    \"\"\"Create vector store from documents\"\"\"\n",
    "    if not documents:\n",
    "        print(\"No documents provided for vector store creation\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        vector_store = FAISS.from_documents(documents, embeddings)\n",
    "        print(f\"Created vector store with {len(documents)} documents\")\n",
    "        return vector_store\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating vector store: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Document processing functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdcd665-8f5b-4843-b3d4-e51382336587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: RAG chain setup\n",
    "def create_rag_chain(llm, vector_store):\n",
    "    \"\"\"Create conversational RAG chain\"\"\"\n",
    "    if not vector_store:\n",
    "        print(\"No vector store provided\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Create memory for conversation\n",
    "        memory = ConversationBufferMemory(\n",
    "            memory_key=config.memory_key,\n",
    "            return_messages=config.return_messages,\n",
    "            output_key='answer'\n",
    "        )\n",
    "        \n",
    "        # Create retriever\n",
    "        retriever = vector_store.as_retriever(\n",
    "            search_type=\"similarity\",\n",
    "            search_kwargs={\"k\": config.top_k}\n",
    "        )\n",
    "        \n",
    "        # Create conversational chain\n",
    "        qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "            llm=llm,\n",
    "            retriever=retriever,\n",
    "            memory=memory,\n",
    "            return_source_documents=True,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        print(\"RAG chain created successfully!\")\n",
    "        return qa_chain\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating RAG chain: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"RAG chain setup function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba85511-faae-4052-a711-062355d76a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Test with sample PDF\n",
    "# Replace 'sample.pdf' with your actual PDF path\n",
    "PDF_PATH = \"sample.pdf\"  # Change this to your PDF path\n",
    "\n",
    "def test_single_pdf():\n",
    "    \"\"\"Test RAG system with single PDF\"\"\"\n",
    "    if not os.path.exists(PDF_PATH):\n",
    "        print(f\"PDF file not found: {PDF_PATH}\")\n",
    "        print(\"Please update PDF_PATH with your actual PDF file path\")\n",
    "        return None, None\n",
    "    \n",
    "    # Load documents\n",
    "    documents = load_pdf_documents([PDF_PATH])\n",
    "    \n",
    "    if not documents:\n",
    "        print(\"No documents loaded\")\n",
    "        return None, None\n",
    "    \n",
    "    # Split documents\n",
    "    splits = split_documents(documents)\n",
    "    \n",
    "    # Create vector store\n",
    "    vector_store = create_vector_store(splits, embeddings)\n",
    "    \n",
    "    if not vector_store:\n",
    "        print(\"Failed to create vector store\")\n",
    "        return None, None\n",
    "    \n",
    "    # Create RAG chain\n",
    "    qa_chain = create_rag_chain(llm, vector_store)\n",
    "    \n",
    "    return qa_chain, vector_store\n",
    "\n",
    "# Test the system\n",
    "print(\"Testing RAG system with single PDF...\")\n",
    "qa_chain, vector_store = test_single_pdf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rag_env)",
   "language": "python",
   "name": "rag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
